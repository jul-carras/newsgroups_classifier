{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75d2917f-625b-46f4-b66a-65ceef5aedc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### US Foods Assessment\n",
    "#### Julian Carrasquillo\n",
    "#### 2023-04-24\n",
    "\n",
    "Resources\n",
    "\n",
    "* [Data Understanding and Reading in](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html)\n",
    "* [SO: Building combinations of dictionary of lists](https://stackoverflow.com/questions/38721847/how-to-generate-all-combination-from-values-in-dict-of-lists-in-python)\n",
    "* [word2vec Tutorial](https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d0292e50-6892-44ce-9a17-1c488786c602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2222c4d-ae89-4ebb-acdb-8aba5ba08d6e",
   "metadata": {},
   "source": [
    "### Base Tutorial\n",
    "\n",
    "The tutorial gave a great look into the best ways to read in the data. Removing heads, footers, and quotes helps to make more generalizable models since a lot can be gleaned from these fields. For example, having a university email in a signature tends to lean towards science-based articles.\n",
    "\n",
    "The overall dataset is quite large, so I picked a random group of categories to develop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b125bb-2fe7-44b9-8870-48808d19fbe2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "len(newsgroups_train['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1ee4a6-640f-4101-8693-71dcae0b1579",
   "metadata": {},
   "source": [
    "From the tutorial, we can use sklearn's built in `TfidfVectorizer`, which builds a sparse matrix based on a balance between a token's term frequency and its inverse document frequency. This weights each token by a measure of relevance to a specific document and relevance to the entire corpus. We can verify the matrix size by checking the output `vectors` shape. The number of rows aligns with the number of articles downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6963b41-f98b-428d-a3ac-e457c060ee4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 101631)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa24b949-5485-4c15-9e12-6797aa47f06b",
   "metadata": {},
   "source": [
    "The tutorial uses a multinomial naive bayes classifier. This trains by counting the number of times each word appears in each category. When we're inferring, a document's words are scored with the most represent category being the prediction. This approach is considered naive because there is assumed independence between words. Despite that, the model still does fairly well with this subset, bringing an F1 score of ~.91."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a3b7175-edec-4ec3-8f00-a9380f42e6b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7002124269782263\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha = .01)\n",
    "clf.fit(vectors,  newsgroups_train.target)\n",
    "\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                     remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "pred = clf.predict(vectors_test)\n",
    "print(metrics.accuracy_score(pred, newsgroups_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a658211-3e44-44d3-afdb-a2c544948da3",
   "metadata": {},
   "source": [
    "## Grid Search on Hyperparameters\n",
    "\n",
    "Between the `TfidfVectorizer` and `MultinomialNB` objects, we have a few hyperparameters we can explore to improve performance. We can build out our own grid search algorithm to try out different combinations and store the results. We'll leverage a function that takes in the various objects along with their parameter set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2fae09-7a88-4741-acc5-0d310c6d91c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_classifier(train, vectorizer, classifier, vectorizer_params = {}, classifier_params = {}):\n",
    "    vectorizer = vectorizer(**vectorizer_params)\n",
    "    vectors = vectorizer.fit_transform(train['data'])\n",
    "    \n",
    "    clf = classifier(**classifier_params)\n",
    "    clf.fit(vectors, train['target'])\n",
    "    \n",
    "    return vectorizer, clf\n",
    "\n",
    "def test_classifier(test, vectorizer, classifier):\n",
    "    vectors = vectorizer.transform(test['data'])\n",
    "    pred = classifier.predict(vectors)\n",
    "    return metrics.accuracy_score(pred, test['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2da66fe-5486-4248-8ddd-8a7afa4eeca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7002124269782263"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify we get the same results as above\n",
    "vectorizer, clf = train_classifier(newsgroups_train, vectorizer = TfidfVectorizer, classifier = MultinomialNB, classifier_params = {'alpha' : .01}) \n",
    "test_classifier(newsgroups_test, vectorizer, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79635d4-a3cf-4a83-808f-ef11b70af4e9",
   "metadata": {},
   "source": [
    "Using python's built-in `itertools`, we can build combinations of parameters for both our vectorizer and algorithms. Using the string as a key for the algorithm, we can include the actual algorithm object from `sklearn` to be passed to our code. Some explanations of the hyperparameters are below:\n",
    "\n",
    "### `TfidfVectorizer`\n",
    "\n",
    "#### `ngram_range`\n",
    "\n",
    "We can see if opening up the word count of each token has any positive effects. Out of the box, `TfidfVectorizer` takes single words as tokens (unigrams). We can expand this to include any arbitrary group of words (2 word combinations = bigrams, 3 words = trigrams, etc) to get some more context. Some examples for why this can be helpful:\n",
    "\n",
    "* we can better capture a baseball players full name - `Jorge` & `Posada` mean more together and more heavily imply an article about baseball.\n",
    "* we can differentiate between `climate change` and the current `political climate`\n",
    "\n",
    "#### `max_df`\n",
    "\n",
    "This parameter essentially acts like a stop word list where the list is generated from the corpus itself. It removes any tokens that show up too many times. As a value between `0` and `1`, it removes any words that show up in more than that proportion of documents.\n",
    "\n",
    "### `MultinomialNB`\n",
    "\n",
    "#### `alpha`\n",
    "\n",
    "This parameter helps with smoothing. Essentially supports situations where the model may see a new word in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e3a8f1-e1f9-4b96-b2ab-cdf7ba04be44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "vector_grid = { 'ngram_range'  : [(1, 1), (1, 2), (2, 2)],\n",
    "               'max_df' : [0.7, 0.8, 0.9, 1.0]}\n",
    "\n",
    "algo_grid = {'MultinomialNB' : {'algo_obj' : MultinomialNB,\n",
    "                                'params' : {'alpha' : [0.01, .05,  0.1, 0.5,  1]}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90a7504e-ab40-4d9f-b80b-3fac52446693",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ngram_range': (1, 1), 'max_df': 0.7},\n",
       " {'ngram_range': (1, 1), 'max_df': 0.8},\n",
       " {'ngram_range': (1, 1), 'max_df': 0.9},\n",
       " {'ngram_range': (1, 1), 'max_df': 1.0},\n",
       " {'ngram_range': (1, 2), 'max_df': 0.7},\n",
       " {'ngram_range': (1, 2), 'max_df': 0.8},\n",
       " {'ngram_range': (1, 2), 'max_df': 0.9},\n",
       " {'ngram_range': (1, 2), 'max_df': 1.0},\n",
       " {'ngram_range': (2, 2), 'max_df': 0.7},\n",
       " {'ngram_range': (2, 2), 'max_df': 0.8},\n",
       " {'ngram_range': (2, 2), 'max_df': 0.9},\n",
       " {'ngram_range': (2, 2), 'max_df': 1.0}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From https://stackoverflow.com/questions/38721847/how-to-generate-all-combination-from-values-in-dict-of-lists-in-python\n",
    "keys, values = zip(*vector_grid.items())\n",
    "vector_groups = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "vector_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dab3464-21fc-44fb-a4a9-0263d9677450",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MultinomialNB': [{'alpha': 0.01},\n",
       "  {'alpha': 0.05},\n",
       "  {'alpha': 0.1},\n",
       "  {'alpha': 0.5},\n",
       "  {'alpha': 1}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_groups = {}\n",
    "for item in algo_grid.keys():\n",
    "    keys, values = zip(*algo_grid[item]['params'].items())\n",
    "    algo_groups.update({item : [dict(zip(keys, v)) for v in itertools.product(*values)]})\n",
    "\n",
    "algo_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10905844-623f-4210-869f-4c5327e2b0b5",
   "metadata": {},
   "source": [
    "Now that our combinations are set up, we can loop through them with our train / test functions and keep track of our results. We extract a validation set from our training data in order to leave the test set as a true evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d34bbfce-9563-4bb2-ad88-02605be76a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(newsgroups_train.data, newsgroups_train.target,  test_size = 0.2, random_state = 42, stratify = newsgroups_train.target)\n",
    "\n",
    "hp_train = {'data' : X_train, 'target' :  y_train}\n",
    "hp_val = {'data' : X_val, 'target' :  y_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e7c0e3d-5a12-46c7-914d-bb54b7146f63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "i = 0\n",
    "for vector_combo in vector_groups:\n",
    "    for key, value in algo_groups.items():\n",
    "        for algo_param in value:\n",
    "            vectorizer, clf = train_classifier(hp_train, vectorizer = TfidfVectorizer, classifier = algo_grid[key]['algo_obj'], vectorizer_params = vector_combo, classifier_params = algo_param)\n",
    "            results.update({i : {'vector_combo' : vector_combo, 'algo' : key, 'algo_param' : algo_param, 'accuracy' : test_classifier(hp_val, vectorizer, clf)}})\n",
    "            i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "558f7791-7cce-432f-880b-381c75728f30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vector_combo    {'ngram_range': (1, 1), 'max_df': 0.7}\n",
       "algo                                     MultinomialNB\n",
       "algo_param                             {'alpha': 0.01}\n",
       "accuracy                                      0.771984\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "best_combo = results_df[np.argmax(results_df.loc['accuracy'])]\n",
    "best_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e40142d-f2ea-483a-9740-2da7aa7962a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.700477960701009"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer, clf = train_classifier(newsgroups_train, vectorizer = TfidfVectorizer, classifier = MultinomialNB, vectorizer_params = best_combo['vector_combo'], classifier_params = best_combo['algo_param'])\n",
    "test_classifier(newsgroups_test, vectorizer, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9830d48-2af9-4f29-9c91-17fa6db93ec8",
   "metadata": {},
   "source": [
    "This improved accuracy by about 0.0002 for this subset! It looks like increasing the word counts in a token did not add value, but removing words showing up in more than 70% of the documents did. From the algorithm perspective, increasing smoothing parameter looks to have helped. \n",
    "\n",
    "However, we can see what words are most associated with each category using the below function from the sklearn tutorial. Many of the words are those you would find in a typical stop list. We can try using the built-in stop_word function to see if we improve results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c4684d6-5bea-4043-83eb-491f8848dca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html\n",
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names_out())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.feature_log_prob_[i])[-10:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbe70307-03d6-40c7-97fa-18a9dd395f21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: be are not in and it you is that of\n",
      "comp.graphics: on that you in graphics it is for and of\n",
      "comp.os.ms-windows.misc: that in file of you for and is it windows\n",
      "comp.sys.ibm.pc.hardware: that have with scsi for of drive is it and\n",
      "comp.sys.mac.hardware: you with that apple for of mac it and is\n",
      "comp.windows.x: server motif for this it in of is and window\n",
      "misc.forsale: it of or in shipping offer 00 and sale for\n",
      "rec.autos: for on is that in it of you and car\n",
      "rec.motorcycles: is my for that in of you it and bike\n",
      "rec.sport.baseball: his they year was is that of in and he\n",
      "rec.sport.hockey: is was hockey team that game of he and in\n",
      "sci.crypt: encryption this in be it is that key and of\n",
      "sci.electronics: this on that for in it you is and of\n",
      "sci.med: be are this you that in it and is of\n",
      "sci.space: you be for that it is in and space of\n",
      "soc.religion.christian: we not you it in god and is that of\n",
      "talk.politics.guns: this they it gun is you in and that of\n",
      "talk.politics.mideast: are not it is israel you that in and of\n",
      "talk.politics.misc: for this are it is you in and that of\n",
      "talk.religion.misc: he god not it in you is and that of\n"
     ]
    }
   ],
   "source": [
    "show_top10(clf, vectorizer, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82c4a695-e3ae-4a8a-afb2-1e5bc14ed277",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7010090281465746"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer, clf = train_classifier(newsgroups_train, vectorizer = TfidfVectorizer, classifier = MultinomialNB, vectorizer_params = {'stop_words' : 'english'}, classifier_params = best_combo['algo_param'])\n",
    "test_classifier(newsgroups_test, vectorizer, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6018fbcb-333c-413e-a91d-9d71ad34e4da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: islam atheists say just religion atheism think don people god\n",
      "comp.graphics: looking format 3d know program file files thanks image graphics\n",
      "comp.os.ms-windows.misc: card problem thanks driver drivers use files dos file windows\n",
      "comp.sys.ibm.pc.hardware: monitor disk thanks pc ide controller bus card scsi drive\n",
      "comp.sys.mac.hardware: know monitor does quadra simms thanks problem drive apple mac\n",
      "comp.windows.x: using windows x11r5 use application thanks widget server motif window\n",
      "misc.forsale: asking email sell price condition new shipping offer 00 sale\n",
      "rec.autos: don ford new good dealer just engine like cars car\n",
      "rec.motorcycles: don just helmet riding like motorcycle ride bikes dod bike\n",
      "rec.sport.baseball: braves players pitching hit runs games game baseball team year\n",
      "rec.sport.hockey: league year nhl games season players play hockey team game\n",
      "sci.crypt: people use escrow nsa keys government chip clipper encryption key\n",
      "sci.electronics: don thanks voltage used know does like circuit power use\n",
      "sci.med: skepticism cadre dsl banks chastity n3jxp pitt gordon geb msg\n",
      "sci.space: just lunar earth shuttle like moon launch orbit nasa space\n",
      "soc.religion.christian: believe faith christian christ bible people christians church jesus god\n",
      "talk.politics.guns: just law firearms government fbi don weapons people guns gun\n",
      "talk.politics.mideast: said arabs arab turkish people armenians armenian jews israeli israel\n",
      "talk.politics.misc: know state clinton president just think tax don government people\n",
      "talk.religion.misc: think don koresh objective christians bible people christian jesus god\n"
     ]
    }
   ],
   "source": [
    "show_top10(clf, vectorizer, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd066834-8ede-48af-a8ea-97b138671d18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.44      0.59      0.51       239\n",
      "           comp.graphics       0.71      0.66      0.68       419\n",
      " comp.os.ms-windows.misc       0.53      0.69      0.60       304\n",
      "comp.sys.ibm.pc.hardware       0.70      0.60      0.65       452\n",
      "   comp.sys.mac.hardware       0.70      0.73      0.71       371\n",
      "          comp.windows.x       0.74      0.80      0.77       365\n",
      "            misc.forsale       0.72      0.80      0.76       352\n",
      "               rec.autos       0.72      0.75      0.74       380\n",
      "         rec.motorcycles       0.73      0.75      0.74       386\n",
      "      rec.sport.baseball       0.81      0.93      0.87       347\n",
      "        rec.sport.hockey       0.93      0.59      0.72       634\n",
      "               sci.crypt       0.77      0.73      0.75       414\n",
      "         sci.electronics       0.58      0.72      0.65       317\n",
      "                 sci.med       0.78      0.84      0.81       365\n",
      "               sci.space       0.80      0.74      0.77       426\n",
      "  soc.religion.christian       0.89      0.59      0.71       600\n",
      "      talk.politics.guns       0.71      0.58      0.64       451\n",
      "   talk.politics.mideast       0.81      0.82      0.81       370\n",
      "      talk.politics.misc       0.45      0.60      0.51       233\n",
      "      talk.religion.misc       0.22      0.50      0.30       107\n",
      "\n",
      "                accuracy                           0.70      7532\n",
      "               macro avg       0.69      0.70      0.68      7532\n",
      "            weighted avg       0.73      0.70      0.71      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectors = vectorizer.transform(newsgroups_test['data'])\n",
    "pred = clf.predict(vectors) \n",
    "print(metrics.classification_report(pred, newsgroups_test['target'], target_names = newsgroups_test['target_names'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a7db8-1c23-48e0-b1a1-20947955f5b6",
   "metadata": {},
   "source": [
    "This improved from greatly from the last set - both in accuracy and more defining words to differentiate topics. Looking at individual categories, the model does best with baseball, middle eastern politics, and science articles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51db912e-7d60-423c-b113-29fa5b4f7af7",
   "metadata": {},
   "source": [
    "## Word2Vec - Another way to Vectorize\n",
    "\n",
    "The estimators in sklearn lean on traditional NLP techniques - bag of words and TF-IDF. We can leverage newer, transformer-based approaches to try and get some context from various words through the use of an attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e3486b6-a980-4c03-b351-6618bc322f08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "462a50e2-190b-4c6e-80ae-a73e84f9916b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i, item in enumerate(newsgroups_train['data']):\n",
    "    item_clean = item.replace(\"\\n\", \" \")\n",
    "    for j in sent_tokenize(item_clean):\n",
    "        temp = []\n",
    "        # tokenize the sentence into words\n",
    "        for k in word_tokenize(j):\n",
    "            temp.append(k.lower())\n",
    "            \n",
    "        data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d8e98c4d-9238-44b0-b6e6-5c8afc2eda53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newsgroups_w2v = gensim.models.Word2Vec(data, min_count = 1,\n",
    "                              vector_size = 100, window = 5)\n",
    "newsgroups_w2v.save(\"word2vec.wordvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "cef0f7c8-561a-4780-af53-78754b1f64da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_vector(data, w2vModel, dim):\n",
    "    \"\"\"\n",
    "    Takes data from the newsgroups_20 set and converts each document into a singular vector\n",
    "    \n",
    "    data: the ['data'] component from the train or test set \n",
    "    w2vModel: object representing word-vector lookup. Can be the .wv object or the KeyedVector object\n",
    "    dim int: the dimension of the expected returned vector. This allows us to fill missing vocabulary with a vector that plays nice with the ultimate output \n",
    "    \"\"\"\n",
    "    doc_vectors = []\n",
    "    for doc in data:\n",
    "        word_vectors = []\n",
    "        if doc.strip() == \"\":\n",
    "            word_vectors.append(np.zeros((dim,)))\n",
    "        else:\n",
    "            for word in word_tokenize(doc):\n",
    "                word_clean = word.replace(\"\\n\", \" \").lower()\n",
    "                try:\n",
    "                    word_vectors.append(w2vModel[word_clean])\n",
    "                except KeyError:\n",
    "                    word_vectors.append(np.zeros((dim,)))\n",
    "        doc_vectors.append(sum(word_vectors))\n",
    "    return doc_vectors\n",
    "\n",
    "def print_int_instance(a_list):\n",
    "    \"\"\"\n",
    "    Prints out the index of each element of a list that is an integer \n",
    "    \"\"\"\n",
    "    for i, item in enumerate(a_list):\n",
    "        if isinstance(item, int):\n",
    "            print(\"Int at index:\", i)\n",
    "            print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0a61bf3c-1ecd-42b8-a017-cf67a28ce8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "homebrew_train = convert_to_vector(data = newsgroups_train['data'], w2vModel = newsgroups_w2v.wv, dim = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b2d35158-989b-40d6-aec5-219300a2b773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_int_instance(homebrew_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "10713097-6d83-41a1-b4ba-9e5b49401377",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "clf = RandomForestClassifier(random_state = 42)\n",
    "clf.fit(homebrew_train, newsgroups_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "58fcdcf3-7c61-42e0-8e7a-c000896d8c7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "homebrew_test = convert_to_vector(data = newsgroups_test['data'], w2vModel = newsgroups_w2v.wv, dim = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "439d881a-9b69-44c3-bfbd-13db2850f448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_int_instance(homebrew_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4b996066-1d6d-4246-9883-9b535d2eba8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25238980350504514\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.24      0.23      0.23       336\n",
      "           comp.graphics       0.24      0.20      0.22       455\n",
      " comp.os.ms-windows.misc       0.20      0.23      0.21       336\n",
      "comp.sys.ibm.pc.hardware       0.27      0.25      0.26       425\n",
      "   comp.sys.mac.hardware       0.14      0.16      0.15       318\n",
      "          comp.windows.x       0.33      0.29      0.31       449\n",
      "            misc.forsale       0.67      0.56      0.61       467\n",
      "               rec.autos       0.20      0.13      0.16       628\n",
      "         rec.motorcycles       0.23      0.18      0.20       529\n",
      "      rec.sport.baseball       0.23      0.17      0.20       539\n",
      "        rec.sport.hockey       0.39      0.36      0.37       439\n",
      "               sci.crypt       0.28      0.25      0.27       448\n",
      "         sci.electronics       0.12      0.18      0.14       257\n",
      "                 sci.med       0.15      0.20      0.17       302\n",
      "               sci.space       0.16      0.18      0.17       352\n",
      "  soc.religion.christian       0.45      0.33      0.38       540\n",
      "      talk.politics.guns       0.10      0.18      0.13       210\n",
      "   talk.politics.mideast       0.37      0.43      0.40       320\n",
      "      talk.politics.misc       0.10      0.27      0.15       120\n",
      "      talk.religion.misc       0.05      0.21      0.08        62\n",
      "\n",
      "                accuracy                           0.25      7532\n",
      "               macro avg       0.25      0.25      0.24      7532\n",
      "            weighted avg       0.28      0.25      0.26      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(homebrew_test)\n",
    "print(metrics.accuracy_score(pred, newsgroups_test['target']))\n",
    "print(metrics.classification_report(pred, newsgroups_test['target'], target_names = newsgroups_test['target_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0f721-89de-4ea5-be99-f309f8c2e242",
   "metadata": {},
   "source": [
    "The above is not a strong model! It could be that our embeddings are not too strong. We can test by looking as some cosine similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4035e642-1b05-491c-9a63-6d82dd28c9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple vs mac -> 0.8163826\n",
      "baseball vs catcher -> 0.6250329\n",
      "space vs rocket -> 0.66309035\n",
      "gaza vs israel -> 0.6368495\n"
     ]
    }
   ],
   "source": [
    "print(\"apple vs mac ->\", newsgroups_w2v.wv.similarity('apple', 'mac'))\n",
    "print(\"baseball vs catcher ->\", newsgroups_w2v.wv.similarity('baseball', 'catcher'))\n",
    "print(\"space vs rocket ->\", newsgroups_w2v.wv.similarity('space', 'rocket'))\n",
    "print(\"gaza vs israel ->\", newsgroups_w2v.wv.similarity('gaza', 'israel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d1d2bd-4db8-4424-a084-707908ebdde5",
   "metadata": {},
   "source": [
    "Perhaps we could get some better performance with stronger embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d1cfa4b5-11af-47f3-af88-b37c26d14e35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "pretrained_w2v = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d5f0a4d2-16fd-499d-b09d-b7cdd6530777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_train = convert_to_vector(data = newsgroups_train['data'], w2vModel = pretrained_w2v, dim = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "5877a425-198a-4ccf-9327-bd3feec1ade3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_int_instance(pretrained_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "80f68544-0454-47f2-a999-a02928cd9529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state = 42)\n",
    "clf.fit(doc_vectors, newsgroups_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7e82c644-d9b5-4038-9338-05b0e81b5b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_test = convert_to_vector(data = newsgroups_test['data'], w2vModel = pretrained_w2v, dim = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3f4d375e-6f52-4a02-aaab-72fb875b16e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43335103558151883\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.29      0.27      0.28       340\n",
      "           comp.graphics       0.36      0.31      0.33       454\n",
      " comp.os.ms-windows.misc       0.32      0.29      0.30       439\n",
      "comp.sys.ibm.pc.hardware       0.34      0.30      0.32       449\n",
      "   comp.sys.mac.hardware       0.18      0.25      0.21       279\n",
      "          comp.windows.x       0.39      0.36      0.38       422\n",
      "            misc.forsale       0.69      0.58      0.63       467\n",
      "               rec.autos       0.51      0.32      0.40       620\n",
      "         rec.motorcycles       0.49      0.38      0.43       508\n",
      "      rec.sport.baseball       0.59      0.43      0.50       552\n",
      "        rec.sport.hockey       0.65      0.63      0.64       412\n",
      "               sci.crypt       0.37      0.50      0.42       291\n",
      "         sci.electronics       0.26      0.44      0.33       235\n",
      "                 sci.med       0.63      0.67      0.65       374\n",
      "               sci.space       0.49      0.59      0.54       326\n",
      "  soc.religion.christian       0.66      0.53      0.59       500\n",
      "      talk.politics.guns       0.42      0.42      0.42       364\n",
      "   talk.politics.mideast       0.57      0.71      0.63       300\n",
      "      talk.politics.misc       0.18      0.44      0.26       130\n",
      "      talk.religion.misc       0.04      0.13      0.06        70\n",
      "\n",
      "                accuracy                           0.43      7532\n",
      "               macro avg       0.42      0.43      0.42      7532\n",
      "            weighted avg       0.46      0.43      0.44      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(pretrained_test)\n",
    "print(metrics.accuracy_score(pred, newsgroups_test['target']))\n",
    "print(metrics.classification_report(pred, newsgroups_test['target'], target_names = newsgroups_test['target_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c2923-2e2e-42cd-86a3-17881ba3f088",
   "metadata": {},
   "source": [
    "We increased the performance, but still have a very poor model. We'd likely benefit from a neural network using these vectors as weights! However, since we are focusing on text featurization, we can leave that as a later exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e4f1e9-d10b-4803-b329-da6b87e0f5c7",
   "metadata": {},
   "source": [
    "## Trying Out an LLM - Google's BERT\n",
    "\n",
    "We can hop on the hype train and try out vectorization using a Large Language Model. [Google's BERT](https://en.wikipedia.org/wiki/BERT_(language_model)) is a model that was built using the relatively new and novel transformer architecture. It stands for **B**idirectional **E**ncoder **R**epresentations from **T**ransformers. While typical transformer models were using everything to the left of a pointer to predict the next word, BERT was looking both directions to try and improve contextual information retrieval. It was set up to model language (via masking tokens and trying to predict them) and next sentence predictions.\n",
    "\n",
    "The model was trained on the Toronto Book Corpus and English Wikipedia. We can use the openly available weights from Tensorflow Hub to embed our text and use that as input into an algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ea0d12-6fa2-4e96-8ea7-38f735165734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7bf2174-6c2e-4019-8640-b5b4617f3ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\") \n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9752935-1564-4f1b-969a-cf4fde9bd3c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_bert, _ , y_train_bert,  _ = train_test_split(newsgroups_train.data, newsgroups_train.target,  train_size = 0.05, random_state = 42, stratify = newsgroups_train.target)\n",
    "X_test_bert, _ , y_test_bert,  _ = train_test_split(newsgroups_test.data, newsgroups_test.target,  train_size = 0.05, random_state = 42, stratify = newsgroups_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "710d47b7-6977-404e-ba9a-740a5176dfa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_preprocessed = bert_preprocess(X_train_bert) \n",
    "train_vectorized = bert_encoder(train_preprocessed)['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5f662c1-a902-4e32-a4c6-5aac9b0b17d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(train_vectorized, y_train_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4b86637-f657-41d1-9d69-513708c23999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preprocessed = bert_preprocess(X_test_bert) \n",
    "test_vectorized = bert_encoder(test_preprocessed)['pooled_output']\n",
    "pred = clf.predict(test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b4e068c-d830-458b-8249-dcee02446e94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2047872340425532"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(pred, y_test_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5cd480-4f4f-458d-871a-3d59698d7c8e",
   "metadata": {},
   "source": [
    "This low score is somewhat expected - we're unable to train on the full dataset due to memory constraints on"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.10.0 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-2.10-cpu-py39-ubuntu20.04-sagemaker-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
